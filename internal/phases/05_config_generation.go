package phases

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/inc4/gonka-nop/internal/config"
	"github.com/inc4/gonka-nop/internal/ui"
)

const (
	defaultModel            = "Qwen/QwQ-32B"
	defaultAttentionBackend = "FLASH_ATTN"
	defaultMLNodeImageTag   = "3.0.12"
	kvCacheDtypeAuto        = "auto"
)

// ConfigGeneration generates configuration files
type ConfigGeneration struct{}

func NewConfigGeneration() *ConfigGeneration {
	return &ConfigGeneration{}
}

func (p *ConfigGeneration) Name() string {
	return "Configuration"
}

func (p *ConfigGeneration) Description() string {
	return "Generating node configuration files with security hardening"
}

func (p *ConfigGeneration) ShouldRun(state *config.State) bool {
	return !state.IsPhaseComplete(p.Name())
}

func (p *ConfigGeneration) Run(_ context.Context, state *config.State) error {
	// Get public IP
	publicIP, err := ui.Input("Enter your server's public IP address:", "")
	if err != nil {
		return err
	}
	state.PublicIP = publicIP

	// Get HuggingFace home directory
	defaultHFHome := "/mnt/shared/huggingface"
	hfHome, err := ui.Input("HuggingFace cache directory:", defaultHFHome)
	if err != nil {
		return err
	}
	state.HFHome = hfHome

	// Create output directory
	err = ui.WithSpinner("Creating output directory", func() error {
		return os.MkdirAll(state.OutputDir, 0750)
	})
	if err != nil {
		return err
	}

	// Generate config.env
	err = ui.WithSpinner("Generating config.env", func() error {
		time.Sleep(300 * time.Millisecond)
		return generateConfigEnv(state)
	})
	if err != nil {
		return err
	}
	ui.Detail("Created: %s/config.env", state.OutputDir)

	// Generate node-config.json
	err = ui.WithSpinner("Generating node-config.json", func() error {
		time.Sleep(300 * time.Millisecond)
		return generateNodeConfig(state)
	})
	if err != nil {
		return err
	}
	ui.Detail("Created: %s/node-config.json", state.OutputDir)

	// Generate docker-compose.yml
	err = ui.WithSpinner("Generating docker-compose.yml", func() error {
		time.Sleep(300 * time.Millisecond)
		return generateDockerCompose(state)
	})
	if err != nil {
		return err
	}
	ui.Detail("Created: %s/docker-compose.yml", state.OutputDir)

	// Generate docker-compose.mlnode.yml
	err = ui.WithSpinner("Generating docker-compose.mlnode.yml", func() error {
		time.Sleep(300 * time.Millisecond)
		return generateMLNodeCompose(state)
	})
	if err != nil {
		return err
	}
	ui.Detail("Created: %s/docker-compose.mlnode.yml", state.OutputDir)

	// Show security configuration summary
	ui.Header("Security Configuration")
	ui.Success("Internal ports bound to 127.0.0.1 (9100, 9200, 5050, 8080)")
	ui.Success("DDoS protection defaults enabled (blocked chain API/RPC/GRPC)")
	ui.Detail("GONKA_API_BLOCKED_ROUTES: /cosmos/*,/nop/*")
	ui.Detail("Pruning: custom (keep-recent=1000, interval=100)")
	if len(state.PersistentPeers) > 0 {
		ui.Detail("Persistent peers: %d configured", len(state.PersistentPeers))
	}

	ui.Success("All configuration files generated")
	return nil
}

func generateConfigEnv(state *config.State) error {
	// Build persistent peers string
	persistentPeers := strings.Join(state.PersistentPeers, ",")
	if persistentPeers == "" {
		// Use default known-good peers
		persistentPeers = strings.Join(defaultPersistentPeers(), ",")
		state.PersistentPeers = defaultPersistentPeers()
	}

	// Model name for ML node
	modelName := state.SelectedModel
	if modelName == "" {
		modelName = defaultModel
	}

	// Attention backend
	attentionBackend := state.AttentionBackend
	if attentionBackend == "" {
		attentionBackend = defaultAttentionBackend
	}

	content := fmt.Sprintf(`# Gonka Node Configuration
# Generated by gonka-nop

# Identity
KEY_NAME=%s
KEYRING_PASSWORD=changeme
ACCOUNT_PUBKEY=%s

# Network
PUBLIC_URL=http://%s:%d
P2P_EXTERNAL_ADDRESS=tcp://%s:%d
API_PORT=%d

# Seed nodes
SEED_API_URL=http://node2.gonka.ai:8000
SEED_NODE_RPC_URL=http://node2.gonka.ai:26657
SEED_NODE_P2P_URL=tcp://node2.gonka.ai:5000

# Internal routing
DAPI_API__POC_CALLBACK_URL=http://api:9100
DAPI_CHAIN_NODE__URL=http://node:26657
DAPI_CHAIN_NODE__P2P_URL=tcp://node:26656

# DDoS Protection
# Block direct access to chain endpoints via proxy
GONKA_API_BLOCKED_ROUTES=/cosmos/*,/nop/*
DISABLE_CHAIN_API=true
DISABLE_CHAIN_RPC=false
DISABLE_CHAIN_GRPC=true

# Sync
SYNC_WITH_SNAPSHOTS=true
TRUSTED_BLOCK_PERIOD=2000

# P2P Configuration
GENESIS_SEEDS=%s

# ML Node
HF_HOME=%s
MODEL_NAME=%s
PORT=8080
INFERENCE_PORT=5050
NODE_CONFIG=./node-config.json
VLLM_ATTENTION_BACKEND=%s

# RPC Servers (for state sync)
RPC_SERVER_URL_1=http://node1.gonka.ai:26657
RPC_SERVER_URL_2=http://node2.gonka.ai:26657
`,
		state.KeyName,
		state.AccountPubKey,
		state.PublicIP,
		state.APIPort,
		state.PublicIP,
		state.P2PPort,
		state.APIPort,
		persistentPeers,
		state.HFHome,
		modelName,
		attentionBackend,
	)

	return os.WriteFile(filepath.Join(state.OutputDir, "config.env"), []byte(content), 0600)
}

func generateNodeConfig(state *config.State) error {
	modelName := state.SelectedModel
	if modelName == "" {
		modelName = defaultModel
	}

	// Build vLLM args with proper formatting
	args := buildVLLMArgs(state)

	// Host should NOT have http:// prefix
	host := state.PublicIP
	host = strings.TrimPrefix(host, "http://")
	host = strings.TrimPrefix(host, "https://")

	content := fmt.Sprintf(`{
  "host": "%s",
  "models": {
    "%s": {
      "args": [%s]
    }
  }
}
`, host, modelName, formatJSONArgs(args))

	return os.WriteFile(filepath.Join(state.OutputDir, "node-config.json"), []byte(content), 0600)
}

// buildVLLMArgs builds the vLLM command-line arguments from state
func buildVLLMArgs(state *config.State) []string {
	args := []string{"--quantization", "fp8"}

	// GPU memory utilization (0.88-0.94, not 0.9/0.99)
	memUtil := state.GPUMemoryUtil
	if memUtil <= 0 {
		memUtil = 0.90
	}
	args = append(args, "--gpu-memory-utilization", fmt.Sprintf("%.2f", memUtil))

	// Tensor parallel size
	if state.TPSize > 1 {
		args = append(args, "--tensor-parallel-size", fmt.Sprintf("%d", state.TPSize))
	}

	// Pipeline parallel size
	if state.PPSize > 1 {
		args = append(args, "--pipeline-parallel-size", fmt.Sprintf("%d", state.PPSize))
	}

	// Max model length
	if state.MaxModelLen > 0 {
		args = append(args, "--max-model-len", fmt.Sprintf("%d", state.MaxModelLen))
	}

	// KV cache dtype (fp8 for tight VRAM)
	if state.KVCacheDtype != "" && state.KVCacheDtype != kvCacheDtypeAuto {
		args = append(args, "--kv-cache-dtype", state.KVCacheDtype)
	}

	return args
}

// formatJSONArgs formats args as a JSON array string: "arg1", "arg2", ...
func formatJSONArgs(args []string) string {
	quoted := make([]string, len(args))
	for i, arg := range args {
		quoted[i] = fmt.Sprintf("%q", arg)
	}
	return strings.Join(quoted, ", ")
}

func generateDockerCompose(state *config.State) error {
	// Build persistent peers for genesis seeds
	persistentPeers := strings.Join(state.PersistentPeers, ",")

	content := fmt.Sprintf(`# Gonka Node Docker Compose
# Generated by gonka-nop
# Security: internal ports bound to 127.0.0.1

services:
  tmkms:
    image: ghcr.io/product-science/tmkms-softsign-with-keygen:0.2.7-post1
    container_name: tmkms
    restart: unless-stopped
    environment:
      - VALIDATOR_LISTEN_ADDRESS=tcp://node:26658
    volumes:
      - .tmkms:/root/.tmkms

  node:
    container_name: node
    image: ghcr.io/product-science/inferenced:0.2.7-post1
    command: ["sh", "./init-docker.sh"]
    volumes:
      - .inference:/root/.inference
    environment:
      - SEED_NODE_RPC_URL=${SEED_NODE_RPC_URL}
      - SEED_NODE_P2P_URL=${SEED_NODE_P2P_URL}
      - SNAPSHOT_INTERVAL=1000
      - SNAPSHOT_KEEP_RECENT=5
      - TRUSTED_BLOCK_PERIOD=${TRUSTED_BLOCK_PERIOD:-2000}
      - KEY_NAME=${KEY_NAME}
      - P2P_EXTERNAL_ADDRESS=${P2P_EXTERNAL_ADDRESS}
      - CONFIG_p2p__allow_duplicate_ip=true
      - CONFIG_p2p__handshake_timeout=30s
      - CONFIG_p2p__dial_timeout=30s
      - TMKMS_PORT=26658
      - SYNC_WITH_SNAPSHOTS=${SYNC_WITH_SNAPSHOTS:-true}
      - RPC_SERVER_URL_1=${RPC_SERVER_URL_1}
      - RPC_SERVER_URL_2=${RPC_SERVER_URL_2}
      - REST_API_ACTIVE=true
      - INIT_ONLY=false
      - IS_GENESIS=false
      - GENESIS_SEEDS=%s
      # Pruning configuration (prevents unbounded disk growth)
      - PRUNING=custom
      - PRUNING_KEEP_RECENT=1000
      - PRUNING_INTERVAL=100
    ports:
      - "5000:26656"  # P2P (public)
      - "26657:26657"  # RPC (public)
    expose:
      - "26658"
    depends_on:
      - tmkms
    restart: always

  api:
    container_name: api
    image: ghcr.io/product-science/api:0.2.7-post1
    volumes:
      - .inference:/root/.inference
      - .dapi:/root/.dapi
      - ${NODE_CONFIG:-./node-config.json}:/root/node_config.json
    depends_on:
      - node
    environment:
      - KEY_NAME=${KEY_NAME}
      - ACCOUNT_PUBKEY=${ACCOUNT_PUBKEY}
      - KEYRING_BACKEND=file
      - KEYRING_PASSWORD=${KEYRING_PASSWORD}
      - DAPI_API__POC_CALLBACK_URL=${DAPI_API__POC_CALLBACK_URL}
      - DAPI_API__PUBLIC_URL=${PUBLIC_URL}
      - DAPI_CHAIN_NODE__SEED_API_URL=${SEED_API_URL}
      - DAPI_CHAIN_NODE__URL=${DAPI_CHAIN_NODE__URL}
      - DAPI_CHAIN_NODE__P2P_URL=${DAPI_CHAIN_NODE__P2P_URL}
      - NODE_CONFIG_PATH=/root/node_config.json
      - DAPI_API__PUBLIC_SERVER_PORT=9000
      - DAPI_API__ML_SERVER_PORT=9100
      - DAPI_API__ADMIN_SERVER_PORT=9200
    ports:
      # SECURITY: Bind internal APIs to localhost only
      - "127.0.0.1:9100:9100"  # ML callback (internal)
      - "127.0.0.1:9200:9200"  # Admin API (internal)
    restart: always
    env_file:
      - config.env

  bridge:
    container_name: bridge
    image: ghcr.io/product-science/bridge:0.2.5-post5
    restart: unless-stopped
    environment:
      - GETH_DATA_DIR=/data/geth
      - PRYSM_DATA_DIR=/data/prysm
      - JWT_SECRET_PATH=/data/jwt/jwt.hex
      - BRIDGE_POSTBLOCK=http://api:9200/admin/v1/bridge/block
      - BRIDGE_GETADDRESSES=http://api:9000/v1/bridge/addresses
      - BEACON_STATE_URL=https://beaconstate.info/
      - PERSISTENT_DB_DIR=/persistent-db
    volumes:
      - .inference-eth/geth:/data/geth
      - .inference-eth/prysm:/data/prysm
      - .inference-eth/jwt:/data/jwt
      - .inference-eth/logs:/var/log
      - .inference-eth/persistent-db:/persistent-db
    depends_on:
      - api

  proxy:
    container_name: proxy
    image: ghcr.io/product-science/proxy:0.2.7-post1
    ports:
      - "${API_PORT:-8000}:80"    # Application service (public)
    environment:
      - NGINX_MODE=${NGINX_MODE:-http}
      - SERVER_NAME=${SERVER_NAME:-}
      - GONKA_API_PORT=9000
      - CHAIN_RPC_PORT=26657
      - CHAIN_API_PORT=1317
      - CHAIN_GRPC_PORT=9090
      - DASHBOARD_PORT=5173
      # DDoS protection: block direct chain endpoints
      - GONKA_API_BLOCKED_ROUTES=${GONKA_API_BLOCKED_ROUTES:-/cosmos/*,/nop/*}
      - DISABLE_CHAIN_API=${DISABLE_CHAIN_API:-true}
      - DISABLE_CHAIN_RPC=${DISABLE_CHAIN_RPC:-false}
      - DISABLE_CHAIN_GRPC=${DISABLE_CHAIN_GRPC:-true}
    depends_on:
      - node
      - api
      - explorer
    restart: unless-stopped

  explorer:
    container_name: explorer
    image: ghcr.io/product-science/explorer:latest
    expose:
      - "5173"
    restart: unless-stopped
`, persistentPeers)

	return os.WriteFile(filepath.Join(state.OutputDir, "docker-compose.yml"), []byte(content), 0600)
}

func generateMLNodeCompose(state *config.State) error {
	modelName := state.SelectedModel
	if modelName == "" {
		modelName = defaultModel
	}

	// Select mlnode image tag based on GPU architecture
	imageTag := state.MLNodeImageTag
	if imageTag == "" {
		imageTag = defaultMLNodeImageTag
	}

	// Select attention backend
	attentionBackend := state.AttentionBackend
	if attentionBackend == "" {
		attentionBackend = defaultAttentionBackend
	}

	content := fmt.Sprintf(`# Gonka ML Node Docker Compose
# Generated by gonka-nop
# Security: ML ports bound to 127.0.0.1

services:
  mlnode:
    container_name: mlnode
    image: ghcr.io/product-science/mlnode:%s
    restart: unless-stopped
    ipc: host
    environment:
      - HF_HOME=%s
      - MODEL_NAME=%s
      - VLLM_ATTENTION_BACKEND=%s
    volumes:
      - %s:%s
      - ./node-config.json:/app/node-config.json
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      # SECURITY: Bind ML ports to localhost only
      - "127.0.0.1:8080:8080"  # PoC endpoint (internal)
      - "127.0.0.1:5050:5050"  # ML inference (internal)
    env_file:
      - config.env
`, imageTag, state.HFHome, modelName, attentionBackend, state.HFHome, state.HFHome)

	return os.WriteFile(filepath.Join(state.OutputDir, "docker-compose.mlnode.yml"), []byte(content), 0600)
}

// defaultPersistentPeers returns the known-good persistent peers for mainnet
func defaultPersistentPeers() []string {
	return []string{
		"780e60b5defca577a160590e0bf51c6bb916d2c6@gonka.spv.re:5000",
		"39ebfea6d2ab91e90c26cb702345cfa2f9bc611b@47.236.26.199:5000",
		"645fbce2dedcc7166f4df7931d2c87ca5188b569@node2.gonka.ai:5000",
		"6140f7090137d93c272ff5ccd863484d1592949d@node3.gonka.ai:5000",
		"947a89a2d5f2af45cb7853f56be0bab8303ffce9@36.189.234.197:18027",
		"78f3279bd30fe6f1b84a9c40c3b97bd74e575981@185.216.21.98:5000",
		"d53a970a40231474fb4092ee64609b975d906085@47.236.19.22:15000",
		"b7dd3863523d78cc5a7c56ddb786395fe49c954a@93.119.168.58:5000",
		"b4ad5a33520ce10d0b7ed5193e2de71e2f1f7a51@36.189.234.237:17240",
		"0772f16cc65cb4d19341b192bd7eba964f11d124@node1.gonka.ai:5000",
		"4d63a0411a257669e794ff62f801550a8449d239@69.19.136.233:5000",
	}
}
